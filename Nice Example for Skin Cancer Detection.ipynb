{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":8805062,"sourceType":"datasetVersion","datasetId":5294941}],"dockerImageVersionId":30733,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## This notebook provides an general overview of the data and trains a baseline EfficientNet-B0 model. You can use the provided code to enhance the baseline model by addressing class imbalance, adding augmentations, tuning hyperparameters, and more.","metadata":{}},{"cell_type":"code","source":"import h5py\nimport io\nimport tqdm\nimport os\n\nimport cv2\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom torchvision.models import efficientnet_b0\n\nplt.style.use('bmh')\nplt.rcParams['figure.figsize'] = (15, 5)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-27T21:47:47.31397Z","iopub.execute_input":"2024-06-27T21:47:47.314411Z","iopub.status.idle":"2024-06-27T21:47:47.322658Z","shell.execute_reply.started":"2024-06-27T21:47:47.314377Z","shell.execute_reply":"2024-06-27T21:47:47.32127Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CFG:\n    seed = 42\n    test_size=0.2\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # dataset parameters\n    img_size = 312\n    img_resize=True # False if pad with zeros instead of resize\n    \n    # model parameters\n    pretrained = False #'DEFAULT'\n    last_layer_hidden_dim = 1280\n    out_dim = 1\n    \n    # train parameters\n    train_batch_size = 64\n    val_batch_size = 128\n    inference_batch_size = 128\n    lr = 1e-3\n    weight_decay = 1e-5\n    train_epochs = 3\n    model_save_folder = \"/kaggle/working/\"\n    model_name = 'baseline_eff0.pt'\n    \n    # score parameters\n    tpr_threshold = 0.8\n    score_normalize=False\n    \n\ndef seed_everything(seed):\n    import random, os\n    import numpy as np\n    import torch\n    \n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\nseed_everything(CFG.seed)\n\nclass PATHS:\n    train_images_h5_path = \"/kaggle/input/isic-2024-challenge/train-image.hdf5\"\n    test_images_h5_path = \"/kaggle/input/isic-2024-challenge/test-image.hdf5\"\n    \n    train_metadata_path = \"/kaggle/input/isic-2024-challenge/train-metadata.csv\"\n    test_metadata_path = \"/kaggle/input/isic-2024-challenge/test-metadata.csv\"\n    \n    submission_path = \"/kaggle/input/isic-2024-challenge/sample_submission.csv\"\n    \nmetadata = pd.read_csv(PATHS.train_metadata_path)\nmetadata_test = pd.read_csv(PATHS.test_metadata_path)\nsubmission = pd.read_csv(PATHS.submission_path)\n\n\n\nTRAIN = True #False if inference run","metadata":{"execution":{"iopub.status.busy":"2024-06-27T21:45:36.947371Z","iopub.execute_input":"2024-06-27T21:45:36.948268Z","iopub.status.idle":"2024-06-27T21:45:47.328398Z","shell.execute_reply.started":"2024-06-27T21:45:36.948231Z","shell.execute_reply":"2024-06-27T21:45:47.326939Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"### Ð¡lass imbalance is very pronounced. 0.09 % of samples has positive class.","metadata":{}},{"cell_type":"code","source":"metadata.target.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T21:45:47.33104Z","iopub.execute_input":"2024-06-27T21:45:47.331445Z","iopub.status.idle":"2024-06-27T21:45:47.361095Z","shell.execute_reply.started":"2024-06-27T21:45:47.331412Z","shell.execute_reply":"2024-06-27T21:45:47.359537Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Most iddx_* columns have a lot of null values. That is different levels of lesion diagnosis.","metadata":{}},{"cell_type":"code","source":"metadata.isnull().sum(0)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T21:45:47.362848Z","iopub.execute_input":"2024-06-27T21:45:47.363263Z","iopub.status.idle":"2024-06-27T21:45:48.028233Z","shell.execute_reply.started":"2024-06-27T21:45:47.363228Z","shell.execute_reply":"2024-06-27T21:45:48.026806Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metadata['iddx_full'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T21:49:44.115775Z","iopub.execute_input":"2024-06-27T21:49:44.116247Z","iopub.status.idle":"2024-06-27T21:49:44.203349Z","shell.execute_reply.started":"2024-06-27T21:49:44.116212Z","shell.execute_reply":"2024-06-27T21:49:44.201892Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Patients Sex, Age and Anatom Site distributions ","metadata":{}},{"cell_type":"code","source":"metadata['sex'].hist()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T21:48:51.121163Z","iopub.execute_input":"2024-06-27T21:48:51.121583Z","iopub.status.idle":"2024-06-27T21:48:51.658745Z","shell.execute_reply.started":"2024-06-27T21:48:51.121548Z","shell.execute_reply":"2024-06-27T21:48:51.65755Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metadata['age_approx'].hist()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T21:48:54.550775Z","iopub.execute_input":"2024-06-27T21:48:54.551208Z","iopub.status.idle":"2024-06-27T21:48:54.952516Z","shell.execute_reply.started":"2024-06-27T21:48:54.551172Z","shell.execute_reply":"2024-06-27T21:48:54.95119Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metadata['anatom_site_general'].hist()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T21:48:55.855762Z","iopub.execute_input":"2024-06-27T21:48:55.856887Z","iopub.status.idle":"2024-06-27T21:48:56.421603Z","shell.execute_reply.started":"2024-06-27T21:48:55.856845Z","shell.execute_reply":"2024-06-27T21:48:56.420386Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### We have aboout 1k unique patients","metadata":{}},{"cell_type":"code","source":"metadata.patient_id.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T21:45:52.810812Z","iopub.execute_input":"2024-06-27T21:45:52.811214Z","iopub.status.idle":"2024-06-27T21:45:52.905459Z","shell.execute_reply.started":"2024-06-27T21:45:52.811183Z","shell.execute_reply":"2024-06-27T21:45:52.904083Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Most labels are quite confident","metadata":{}},{"cell_type":"code","source":"metadata.tbp_lv_dnn_lesion_confidence.hist()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T21:57:19.399712Z","iopub.execute_input":"2024-06-27T21:57:19.401015Z","iopub.status.idle":"2024-06-27T21:57:19.777126Z","shell.execute_reply.started":"2024-06-27T21:57:19.400968Z","shell.execute_reply":"2024-06-27T21:57:19.775879Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### If condiser only malignant labels then we get different distribution with more density at low confidence","metadata":{}},{"cell_type":"code","source":"metadata[metadata.target == 1].tbp_lv_dnn_lesion_confidence.hist()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T21:57:21.474158Z","iopub.execute_input":"2024-06-27T21:57:21.474678Z","iopub.status.idle":"2024-06-27T21:57:21.831182Z","shell.execute_reply.started":"2024-06-27T21:57:21.474634Z","shell.execute_reply":"2024-06-27T21:57:21.829888Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Read h5 images. Train images already provided in train-image folder. Here, to demosntarte reading, I extract them from h5.","metadata":{}},{"cell_type":"code","source":"def read_images_from_hdf5(file_path):\n    with h5py.File(file_path, 'r') as file:\n        ids_list = list(file.keys())        \n        ids_images = {}\n        for img_id in tqdm.tqdm(ids_list):\n            image_data = file[img_id][()]\n            image = Image.open(io.BytesIO(image_data))\n            ids_images[img_id] = np.array(image)\n    return ids_images","metadata":{"execution":{"iopub.status.busy":"2024-06-27T21:50:09.830581Z","iopub.execute_input":"2024-06-27T21:50:09.831074Z","iopub.status.idle":"2024-06-27T21:50:09.838993Z","shell.execute_reply.started":"2024-06-27T21:50:09.831038Z","shell.execute_reply":"2024-06-27T21:50:09.837677Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nif TRAIN:\n    images_train = read_images_from_hdf5(PATHS.train_images_h5_path)\nimages_test = read_images_from_hdf5(PATHS.test_images_h5_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T21:50:10.056725Z","iopub.execute_input":"2024-06-27T21:50:10.057162Z","iopub.status.idle":"2024-06-27T21:56:45.284933Z","shell.execute_reply.started":"2024-06-27T21:50:10.057129Z","shell.execute_reply":"2024-06-27T21:56:45.283577Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Let's check image size distributions.","metadata":{"execution":{"iopub.status.busy":"2024-06-27T16:12:36.78834Z","iopub.execute_input":"2024-06-27T16:12:36.789245Z","iopub.status.idle":"2024-06-27T16:12:36.799022Z","shell.execute_reply.started":"2024-06-27T16:12:36.789195Z","shell.execute_reply":"2024-06-27T16:12:36.797653Z"}}},{"cell_type":"code","source":"if TRAIN:\n    imgs_sizes = [img.shape for img in images_train.values()]","metadata":{"execution":{"iopub.status.busy":"2024-06-27T21:57:52.368731Z","iopub.execute_input":"2024-06-27T21:57:52.369157Z","iopub.status.idle":"2024-06-27T21:57:52.552443Z","shell.execute_reply.started":"2024-06-27T21:57:52.369124Z","shell.execute_reply":"2024-06-27T21:57:52.551219Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### height","metadata":{}},{"cell_type":"code","source":"if TRAIN:\n    plt.hist([i[0] for i in imgs_sizes]);","metadata":{"execution":{"iopub.status.busy":"2024-06-27T21:57:53.998478Z","iopub.execute_input":"2024-06-27T21:57:53.998956Z","iopub.status.idle":"2024-06-27T21:57:56.44838Z","shell.execute_reply.started":"2024-06-27T21:57:53.998922Z","shell.execute_reply":"2024-06-27T21:57:56.447167Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### width\n","metadata":{}},{"cell_type":"code","source":"if TRAIN:\n    plt.hist([i[1] for i in imgs_sizes]);","metadata":{"execution":{"iopub.status.busy":"2024-06-27T21:57:58.154619Z","iopub.execute_input":"2024-06-27T21:57:58.15511Z","iopub.status.idle":"2024-06-27T21:58:00.546648Z","shell.execute_reply.started":"2024-06-27T21:57:58.155075Z","shell.execute_reply":"2024-06-27T21:58:00.544883Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### You can see that min max of Images h/w is 41/269. And all images have equal hxw ratio = 1","metadata":{"execution":{"iopub.status.busy":"2024-06-27T16:14:36.898358Z","iopub.execute_input":"2024-06-27T16:14:36.898738Z","iopub.status.idle":"2024-06-27T16:14:36.904096Z","shell.execute_reply.started":"2024-06-27T16:14:36.898709Z","shell.execute_reply":"2024-06-27T16:14:36.903299Z"}}},{"cell_type":"code","source":"if TRAIN:\n    print(f\"Min height within train images = {np.min([i[0] for i in imgs_sizes])}, Max height within train images = {np.max([i[0] for i in imgs_sizes])}\")\n    print(f\"Min width within train images = {np.min([i[1] for i in imgs_sizes])}, Max width within train images = {np.max([i[1] for i in imgs_sizes])}\")\n    print(f\"Height and width among images are equal = {[i[1] for i in imgs_sizes] == [i[0] for i in imgs_sizes]}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-27T21:58:00.54997Z","iopub.execute_input":"2024-06-27T21:58:00.550499Z","iopub.status.idle":"2024-06-27T21:58:00.871833Z","shell.execute_reply.started":"2024-06-27T21:58:00.550454Z","shell.execute_reply":"2024-06-27T21:58:00.870582Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Baseline efficientnet b0 training","metadata":{}},{"cell_type":"code","source":"class ISIC2024Dataset(Dataset):\n    def __init__(self, \n                 metadata: pd.DataFrame, \n                 ids_images: dict,\n                 img_resize: bool=True,\n                 test: bool=False):\n        \n        self.metadata = metadata\n        self.ids_images = ids_images\n        self.img_resize = img_resize\n        self.test = test\n\n    def __len__(self):\n        return len(self.metadata)\n    \n    def pad_img(self, img):\n        pad_y = CFG.img_size - img.shape[0]\n        pad_x = CFG.img_size - img.shape[1]\n        padded_img = np.pad(img, \n                       ((pad_y//2, pad_y//2 + pad_y%2), \n                        (pad_x//2, pad_x//2 + pad_x%2), \n                        (0, 0)),\n                       mode='constant', constant_values=0)\n        return padded_img\n\n    def __getitem__(self, item):\n        isic_row = self.metadata.iloc[item]\n        isic_id = isic_row.isic_id\n        image = self.ids_images[isic_id]\n        if self.img_resize:\n            image = cv2.resize(image, dsize=(CFG.img_size, CFG.img_size))\n        else:\n            image = self.pad_img(image)\n        if self.test:\n            return image\n        label = isic_row.target\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:07:27.354981Z","iopub.execute_input":"2024-06-27T17:07:27.356022Z","iopub.status.idle":"2024-06-27T17:07:27.365481Z","shell.execute_reply.started":"2024-06-27T17:07:27.355984Z","shell.execute_reply":"2024-06-27T17:07:27.364757Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if TRAIN:\n    train, val = train_test_split(metadata, \n                                 stratify=metadata.target,\n                                 test_size=CFG.test_size,\n                                 random_state=CFG.seed)\n    print(train.target.value_counts(), val.target.value_counts())","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:01:17.574105Z","iopub.execute_input":"2024-06-27T17:01:17.574465Z","iopub.status.idle":"2024-06-27T17:01:18.300781Z","shell.execute_reply.started":"2024-06-27T17:01:17.574435Z","shell.execute_reply":"2024-06-27T17:01:18.299767Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if TRAIN:\n    dataset_train = ISIC2024Dataset(train, images_train, img_resize=CFG.img_resize)\n    dataset_val = ISIC2024Dataset(val, images_train, img_resize=CFG.img_resize)\n    train_dataloader = torch.utils.data.DataLoader(\n            dataset_train,\n            batch_size=CFG.train_batch_size,\n            num_workers=0,\n            shuffle=True,\n            pin_memory=True\n    )\n    val_dataloader = torch.utils.data.DataLoader(\n            dataset_val,\n            batch_size=CFG.val_batch_size,\n            num_workers=0,\n            shuffle=False,\n            pin_memory=True,\n        )\n\n\ndataset_test = ISIC2024Dataset(metadata_test, images_test, img_resize=CFG.img_resize, test=True)\ntest_dataloader = torch.utils.data.DataLoader(\n        dataset_test,\n        batch_size=CFG.inference_batch_size,\n        num_workers=0,\n        shuffle=False,\n        pin_memory=True,\n    )\n","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:07:48.188085Z","iopub.execute_input":"2024-06-27T17:07:48.188451Z","iopub.status.idle":"2024-06-27T17:07:48.196158Z","shell.execute_reply.started":"2024-06-27T17:07:48.18842Z","shell.execute_reply":"2024-06-27T17:07:48.195324Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Let's check dataset ","metadata":{}},{"cell_type":"code","source":"dataset_test[0].shape == (CFG.img_size, CFG.img_size, 3)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:02:04.4932Z","iopub.execute_input":"2024-06-27T17:02:04.493567Z","iopub.status.idle":"2024-06-27T17:02:04.500147Z","shell.execute_reply.started":"2024-06-27T17:02:04.493519Z","shell.execute_reply":"2024-06-27T17:02:04.49926Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(dataset_test[0])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:07:52.102203Z","iopub.execute_input":"2024-06-27T17:07:52.102569Z","iopub.status.idle":"2024-06-27T17:07:52.473533Z","shell.execute_reply.started":"2024-06-27T17:07:52.10253Z","shell.execute_reply":"2024-06-27T17:07:52.47267Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_epoch(train_loader, model, optimizer, criterion, scheduler, device):\n    \"\"\"One epoch training pass.\"\"\"\n    model.train()\n    scaler = torch.cuda.amp.GradScaler(enabled=True)\n    losses = []\n    with tqdm.notebook.tqdm(train_loader, unit=\"train_batch\", desc='Train') as tqdm_train_loader:\n        for step, batch in enumerate(tqdm_train_loader):\n            \n            X = batch[0].to(device).float()\n            y = batch[1].to(device).view(-1, 1).float()\n            \n            y_preds = model(X)\n            loss = criterion(y_preds, y)\n            \n            losses.append(loss.item())\n            scaler.scale(loss).backward()\n\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n            if scheduler is not None:\n                scheduler.step()\n\n    return np.mean(losses)\n\ndef validation(valid_loader, model, criterion, device):\n    model.eval() \n    losses = []\n    preds = []\n    with tqdm.notebook.tqdm(valid_loader, unit=\"valid_batch\", desc='Validation') as tqdm_valid_loader:\n        for step, batch in enumerate(tqdm_valid_loader):\n            X = batch[0].to(device).float()\n            y = batch[1].to(device).view(-1, 1).float()\n            with torch.no_grad():\n                y_preds = model(X)\n                loss = criterion(y_preds, y)                \n                preds.append(y_preds.sigmoid().cpu().numpy())               \n            losses.append(loss.item())\n    preds = np.concatenate(preds, 0)\n    return np.mean(losses), preds\n\ndef inference(valid_loader, model, device):\n    model.eval() \n    preds = []\n    with tqdm.notebook.tqdm(valid_loader, unit=\"inference_batch\", desc='Inference') as tqdm_valid_loader:\n        for step, batch in enumerate(tqdm_valid_loader):\n            X = batch.to(device).float()\n            with torch.no_grad():\n                y_preds = model(X)\n                preds.append(y_preds.sigmoid().cpu().numpy())               \n    preds = np.concatenate(preds, 0)\n    return preds","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:16:36.988596Z","iopub.execute_input":"2024-06-27T17:16:36.988947Z","iopub.status.idle":"2024-06-27T17:16:37.003449Z","shell.execute_reply.started":"2024-06-27T17:16:36.988918Z","shell.execute_reply":"2024-06-27T17:16:37.002563Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ISIC2024Model(nn.Module):\n    def __init__(self, \n                 config):\n        \n        super(ISIC2024Model, self).__init__()\n        self.backbone = efficientnet_b0(pretrained=config.pretrained)\n        self.backbone = torch.nn.Sequential(*(list(self.backbone.children())[:-1]))\n        self.head = nn.Sequential(nn.Linear(config.last_layer_hidden_dim, config.out_dim))                                    \n\n    def forward(self, \n                input):\n        input = input.permute(0, 3, 1, 2)\n        \n        x = self.backbone(input)\n        x = self.head(x.flatten(1))\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-06-27T16:45:19.426627Z","iopub.execute_input":"2024-06-27T16:45:19.426924Z","iopub.status.idle":"2024-06-27T16:45:19.43356Z","shell.execute_reply.started":"2024-06-27T16:45:19.4269Z","shell.execute_reply":"2024-06-27T16:45:19.432594Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### The partial AUC score implementation","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import roc_curve, auc\n\ndef compute_pauc(y_true, y_scores, tpr_threshold=0.8):\n    \"\"\"\n    Compute the partial AUC above a given TPR threshold.\n\n    Parameters:\n    y_true (np.array): True binary labels.\n    y_scores (np.array): Target scores.\n    tpr_threshold (float): TPR threshold above which to compute the pAUC.\n    Returns:\n    float: The partial AUC above the given TPR threshold.\n    \"\"\"\n    # Compute ROC curve\n    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n\n    # Find the indices where the TPR is above the threshold\n    tpr_above_threshold_indices = np.where(tpr >= tpr_threshold)[0]\n\n    if len(tpr_above_threshold_indices) == 0:\n        return 0.0\n\n    # Extract the indices for the ROC segment above the threshold\n    start_index = tpr_above_threshold_indices[0] \n    fpr_above_threshold = fpr[start_index:]\n    tpr_above_threshold = tpr[start_index:] - tpr_threshold\n\n#     print(fpr_above_threshold, tpr_above_threshold, thresholds[start_index:])\n    # Compute partial AUC\n    partial_auc = auc(fpr_above_threshold, tpr_above_threshold)\n    \n    return partial_auc\n\n# Example usage\ny_true = np.array([0, 1, 0])\ny_scores = np.array([0.1, 0.4, 0.35])\n\npauc = compute_pauc(y_true, y_scores)\nprint(f'Partial AUC above 80% TPR: {pauc:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:11:10.831456Z","iopub.execute_input":"2024-06-27T17:11:10.832257Z","iopub.status.idle":"2024-06-27T17:11:10.843095Z","shell.execute_reply.started":"2024-06-27T17:11:10.832225Z","shell.execute_reply":"2024-06-27T17:11:10.842183Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_path = os.path.join(CFG.model_save_folder, model_name)\nprint(save_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T16:45:22.614274Z","iopub.execute_input":"2024-06-27T16:45:22.614653Z","iopub.status.idle":"2024-06-27T16:45:22.619804Z","shell.execute_reply.started":"2024-06-27T16:45:22.614622Z","shell.execute_reply":"2024-06-27T16:45:22.618746Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### I trained the baseline model locally on RTX 3090. The average epoch time was ~20 minutes.","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:03:36.408808Z","iopub.execute_input":"2024-06-27T17:03:36.409399Z","iopub.status.idle":"2024-06-27T17:03:36.41325Z","shell.execute_reply.started":"2024-06-27T17:03:36.409366Z","shell.execute_reply":"2024-06-27T17:03:36.412407Z"}}},{"cell_type":"code","source":"model = ISIC2024Model(CFG)\nmodel = model.to(CFG.device)\n\nif TRAIN:\n    optimizer = torch.optim.AdamW(model.parameters(), \n                                  lr=CFG.lr, \n                                  weight_decay=CFG.weight_decay)\n    criterion = nn.BCEWithLogitsLoss()\n    score_best = 0 \n    for e in range(CFG.train_epochs):\n        loss_mean = train_epoch(train_dataloader, model, optimizer, criterion, None, CFG.device)\n        loss_val, preds = validation(val_dataloader, model, criterion, CFG.device)\n        score = compute_pauc(val.target.values, \n                             preds, \n                             tpr_threshold=CFG.tpr_threshold)\n        if score > score_best:\n            score_best = score\n            torch.save({\n                'model': model.state_dict(), \n                'predictions': preds\n            },\n            save_path)\n\n        print(f\"Train loss = {loss_mean}. Val loss = {loss_val}. Val scor = {score}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-27T16:45:22.798014Z","iopub.execute_input":"2024-06-27T16:45:22.79875Z","iopub.status.idle":"2024-06-27T16:45:23.246552Z","shell.execute_reply.started":"2024-06-27T16:45:22.79872Z","shell.execute_reply":"2024-06-27T16:45:23.245599Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"model.load_state_dict(torch.load(save_path)['model'])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T16:45:26.853158Z","iopub.execute_input":"2024-06-27T16:45:26.854003Z","iopub.status.idle":"2024-06-27T16:45:27.322167Z","shell.execute_reply.started":"2024-06-27T16:45:26.853969Z","shell.execute_reply":"2024-06-27T16:45:27.321268Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preds = inference(test_dataloader, model, CFG.device)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T17:16:41.3905Z","iopub.execute_input":"2024-06-27T17:16:41.390927Z","iopub.status.idle":"2024-06-27T17:16:41.436409Z","shell.execute_reply.started":"2024-06-27T17:16:41.390899Z","shell.execute_reply":"2024-06-27T17:16:41.435595Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission['isic_id'] = metadata_test['isic_id'].to_list()\nsubmission['target'] = preds\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T16:45:42.209458Z","iopub.execute_input":"2024-06-27T16:45:42.209832Z","iopub.status.idle":"2024-06-27T16:45:42.219415Z","shell.execute_reply.started":"2024-06-27T16:45:42.209804Z","shell.execute_reply":"2024-06-27T16:45:42.218733Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}